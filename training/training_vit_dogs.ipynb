{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169f3a4e-9b7b-42d1-ac4b-245f11e6ccbd",
   "metadata": {},
   "source": [
    "### 这个文档用于使用重新训练，加入tensorboard可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97deeb0e-a39d-411a-86a7-6c5e4b3e470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/lib/python3.10/site-packages (1.6.0)\n",
      "Collecting seaborn\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: numpy>=1.19.5 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda3/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /root/miniconda3/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /root/miniconda3/lib/python3.10/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install tensorboard\n",
    "!pip install scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ee14ce-7e0a-4b3a-a69f-c81d66769619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-01-10 23:06:11'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a492112-f3e5-49e7-baf3-e5c46295762d",
   "metadata": {},
   "source": [
    "# HYPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b6258d-fcf0-472b-b4c0-b4e226428c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f93ebda4590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95c8702-7724-430f-92f3-aa837332c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/Images\"\n",
    "#hyperparameter:\n",
    "learning_rate = 5e-5\n",
    "batch_size = 128\n",
    "#adam paras:\n",
    "betas=(0.9, 0.999)\n",
    "eps=1e-8\n",
    "\n",
    "training_steps = 1000\n",
    "num_classes = 120\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ac7fa8-2c9c-4753-b43d-73cc9a692aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3ca159-f43f-4daf-ac6b-d871cd831295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6af4d30-0e9d-4e37-8bab-5945edec134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.data.IMAGENET_DEFAULT_MEAN,timm.data.IMAGENET_DEFAULT_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbfe25-f569-4590-9966-c9299ae6e3f0",
   "metadata": {},
   "source": [
    "# DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9205a1-48f4-46c5-84c1-d676c9f17985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "trans_ = T.Compose([\n",
    "    T.Resize((224, 224)), \n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=timm.data.IMAGENET_DEFAULT_MEAN, std=timm.data.IMAGENET_DEFAULT_STD)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=trans_)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655045d-ad4e-45ec-8a5b-9536551755d5",
   "metadata": {},
   "source": [
    "### 计算每个epoch的batch数为step数，每个step都会更新梯度，乘以epochs得到总的steps\n",
    "- = 20580 * 80% /128 = 128.625 向上取整\n",
    "- 总的steps = 129 * numepochs = 1935\n",
    "- 实际训练时可能会提前终止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b8679e-d589-4358-b498-05ab48d59e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5d4d65-cb1b-4e23-879a-48c126388df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 224, 224]), torch.Size([128]), 645)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = len(train_loader) * num_epochs\n",
    "images, labels = next(iter(train_loader))\n",
    "images.size(),labels.size(),num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06aed3b-6061-4ff1-a022-47194592ca29",
   "metadata": {},
   "source": [
    "# MODEL_PRETRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebaa06b-2517-426a-8a69-214eff44b52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at /workspaces and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "model_path = '/workspaces'\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(model_path,num_labels = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb098da-7142-4561-95db-90361c04ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cef6a7-b152-4761-bba0-515f3d90ef17",
   "metadata": {},
   "source": [
    "# FINE_TUNING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e071ad4-cd53-4e3c-9e0b-8b2539a283e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1526c00-473d-4f01-9a6e-709ab9a71efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8619ccc-67bc-4c5b-97f3-16ee895c65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 TensorBoard\n",
    "writer = SummaryWriter(log_dir=\"./runs/vit_finetune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647f638-baf6-45e6-bbe5-abc9eaad8586",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "<!-- from transformers import Adafactor, Trainer, TrainingArguments\n",
    "\n",
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"steps\",            # 每隔一定步数进行评估\n",
    "    save_strategy=\"steps\",                  # 每隔一定步数保存模型\n",
    "    learning_rate=5e-5,                     # 学习率\n",
    "    gradient_accumulation_steps=4,          # 梯度累积\n",
    "    gradient_checkpointing=True,            # 启用梯度检查点\n",
    "    optim=\"adafactor\",                      # 使用 Adafactor 优化器\n",
    "    max_steps=1000,                          # 总训练步数\n",
    "    eval_delay=0,                           # 评估延迟\n",
    "    logging_steps=100,                      # 每100步进行一次日志记录\n",
    "    save_steps=200,                         # 每200步保存一次模型\n",
    "    load_best_model_at_end=True,            # 在训练结束时加载最佳模型\n",
    "    metric_for_best_model=\"f1\",             # 评估标准\n",
    "    greater_is_better=True,                 # F1 分数越高越好\n",
    "    report_to=\"mlflow\",                     # 将日志报告到 MLflow\n",
    "    save_total_limit=2,                     # 最多保存2个模型\n",
    "    output_dir = './output'\n",
    ")\n",
    "\n",
    "# 使用 Adafactor 优化器，指定学习率和 beta 值\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(),        # 使用 training_args 中的学习率\n",
    "    eps=1e-8,                               # 防止数值问题\n",
    "    # betas=(0.9, 0.999),                     # beta 设置为（0.9， 0.999）\n",
    "    weight_decay=0.01,                      # 权重衰减\n",
    "    relative_step=True,                     # 使用相对步长\n",
    "    warmup_init=True                        # 启用热启动\n",
    ")\n",
    "\n",
    "# 使用 Trainer API 进行训练\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,            # 训练数据集\n",
    "    eval_dataset=val_dataset,              # 验证数据集\n",
    "    optimizers=(optimizer, None),           # 使用自定义优化器\n",
    ")\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa3239-6c4a-4f12-8934-e34232e4fcc7",
   "metadata": {},
   "source": [
    "\n",
    "### 传统SGD：https://pytorch.org/docs/stable/generated/torch.optim.SGD.html \n",
    "$$\n",
    "\\theta_t = \\theta_{t-1} - \\eta \\nabla_\\theta J(\\theta_{t-1}),\n",
    "$$\n",
    "\n",
    "### Adam：https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "- **step1:**\n",
    "    $$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_\\theta J(\\theta_{t-1}),\n",
    "$$\n",
    "\n",
    "    $$\n",
    "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\left(\\nabla_\\theta J(\\theta_{t-1})\\right)^2,\n",
    "$$\n",
    "\n",
    "- **step2:**\n",
    "\n",
    "    $$\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t},\n",
    "$$ \n",
    "- **step3:**\n",
    "\n",
    "    $$\n",
    "\\theta_t = \\theta_{t-1} - \\frac{\\eta \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon},\n",
    "$$\n",
    "\n",
    "**优点：** Adam的算法可以简单的理解为RMSProp和动量优化的结合：\n",
    "- 其中动量优化提供了动态调整学习率的思路，可以有效缓和震荡问题\n",
    "- RMSProp可以理解为AdaGrad与指数加权移动平均算法的结合，其中：\n",
    "    - AdaGrad对于不同更新力度的参数定制不同的学习率\n",
    "    - 指数加权移动平均算法使AdaGrad梯度累加更加平滑，避免了早停"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbae23bc-a01d-42c0-8ef9-2c44701b0d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [10/129], Loss: 4.7561, Accuracy: 2.50%\n",
      "Epoch [1/5], Step [20/129], Loss: 4.6905, Accuracy: 6.64%\n",
      "Epoch [1/5], Step [30/129], Loss: 4.6250, Accuracy: 11.02%\n",
      "Epoch [1/5], Step [40/129], Loss: 4.5335, Accuracy: 16.70%\n",
      "Epoch [1/5], Step [50/129], Loss: 4.4544, Accuracy: 22.48%\n",
      "Epoch [1/5], Step [60/129], Loss: 4.3607, Accuracy: 28.35%\n",
      "Epoch [1/5], Step [70/129], Loss: 4.2749, Accuracy: 33.02%\n",
      "Epoch [1/5], Step [80/129], Loss: 4.1992, Accuracy: 36.72%\n",
      "Epoch [1/5], Step [90/129], Loss: 4.1109, Accuracy: 40.03%\n",
      "Epoch [1/5], Step [100/129], Loss: 4.0191, Accuracy: 42.95%\n",
      "Epoch [1/5], Step [110/129], Loss: 3.9443, Accuracy: 45.45%\n",
      "Epoch [1/5], Step [120/129], Loss: 3.8663, Accuracy: 47.70%\n",
      "Epoch [1/5] Eval Loss: 3.7515, Eval Accuracy: 75.30%, Precision: 0.81, Recall: 0.75, F1-Score: 0.74\n",
      "Epoch [2/5], Step [10/129], Loss: 3.6780, Accuracy: 79.77%\n",
      "Epoch [2/5], Step [20/129], Loss: 3.6194, Accuracy: 79.10%\n",
      "Epoch [2/5], Step [30/129], Loss: 3.5355, Accuracy: 79.74%\n",
      "Epoch [2/5], Step [40/129], Loss: 3.4659, Accuracy: 79.98%\n",
      "Epoch [2/5], Step [50/129], Loss: 3.3855, Accuracy: 80.23%\n",
      "Epoch [2/5], Step [60/129], Loss: 3.3736, Accuracy: 80.09%\n",
      "Epoch [2/5], Step [70/129], Loss: 3.2962, Accuracy: 80.23%\n",
      "Epoch [2/5], Step [80/129], Loss: 3.2382, Accuracy: 80.36%\n",
      "Epoch [2/5], Step [90/129], Loss: 3.1861, Accuracy: 80.49%\n",
      "Epoch [2/5], Step [100/129], Loss: 3.1333, Accuracy: 80.53%\n",
      "Epoch [2/5], Step [110/129], Loss: 3.0792, Accuracy: 80.74%\n",
      "Epoch [2/5], Step [120/129], Loss: 3.0260, Accuracy: 80.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] Eval Loss: 3.0054, Eval Accuracy: 79.82%, Precision: 0.83, Recall: 0.80, F1-Score: 0.78\n",
      "Epoch [3/5], Step [10/129], Loss: 2.8433, Accuracy: 87.89%\n",
      "Epoch [3/5], Step [20/129], Loss: 2.8179, Accuracy: 87.93%\n",
      "Epoch [3/5], Step [30/129], Loss: 2.7723, Accuracy: 87.71%\n",
      "Epoch [3/5], Step [40/129], Loss: 2.7318, Accuracy: 87.56%\n",
      "Epoch [3/5], Step [50/129], Loss: 2.6909, Accuracy: 87.44%\n",
      "Epoch [3/5], Step [60/129], Loss: 2.6440, Accuracy: 87.57%\n",
      "Epoch [3/5], Step [70/129], Loss: 2.5996, Accuracy: 87.51%\n",
      "Epoch [3/5], Step [80/129], Loss: 2.5394, Accuracy: 87.71%\n",
      "Epoch [3/5], Step [90/129], Loss: 2.5371, Accuracy: 87.68%\n",
      "Epoch [3/5], Step [100/129], Loss: 2.5206, Accuracy: 87.66%\n",
      "Epoch [3/5], Step [110/129], Loss: 2.4905, Accuracy: 87.76%\n",
      "Epoch [3/5], Step [120/129], Loss: 2.4454, Accuracy: 87.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] Eval Loss: 2.5430, Eval Accuracy: 82.03%, Precision: 0.85, Recall: 0.82, F1-Score: 0.81\n",
      "Epoch [4/5], Step [10/129], Loss: 2.3022, Accuracy: 90.86%\n",
      "Epoch [4/5], Step [20/129], Loss: 2.2665, Accuracy: 91.56%\n",
      "Epoch [4/5], Step [30/129], Loss: 2.2695, Accuracy: 91.09%\n",
      "Epoch [4/5], Step [40/129], Loss: 2.2569, Accuracy: 91.04%\n",
      "Epoch [4/5], Step [50/129], Loss: 2.2094, Accuracy: 91.00%\n",
      "Epoch [4/5], Step [60/129], Loss: 2.2304, Accuracy: 90.85%\n",
      "Epoch [4/5], Step [70/129], Loss: 2.1755, Accuracy: 90.99%\n",
      "Epoch [4/5], Step [80/129], Loss: 2.1588, Accuracy: 90.99%\n",
      "Epoch [4/5], Step [90/129], Loss: 2.1454, Accuracy: 90.96%\n",
      "Epoch [4/5], Step [100/129], Loss: 2.1252, Accuracy: 91.09%\n",
      "Epoch [4/5], Step [110/129], Loss: 2.1153, Accuracy: 90.94%\n",
      "Epoch [4/5], Step [120/129], Loss: 2.0969, Accuracy: 90.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] Eval Loss: 2.2910, Eval Accuracy: 82.44%, Precision: 0.85, Recall: 0.82, F1-Score: 0.81\n",
      "Epoch [5/5], Step [10/129], Loss: 2.0233, Accuracy: 92.81%\n",
      "Epoch [5/5], Step [20/129], Loss: 2.0089, Accuracy: 92.89%\n",
      "Epoch [5/5], Step [30/129], Loss: 2.0160, Accuracy: 92.53%\n",
      "Epoch [5/5], Step [40/129], Loss: 1.9736, Accuracy: 92.60%\n",
      "Epoch [5/5], Step [50/129], Loss: 1.9945, Accuracy: 92.20%\n",
      "Epoch [5/5], Step [60/129], Loss: 1.9777, Accuracy: 92.16%\n",
      "Epoch [5/5], Step [70/129], Loss: 1.9549, Accuracy: 92.20%\n",
      "Epoch [5/5], Step [80/129], Loss: 1.9726, Accuracy: 92.21%\n",
      "Epoch [5/5], Step [90/129], Loss: 1.9505, Accuracy: 92.27%\n",
      "Epoch [5/5], Step [100/129], Loss: 1.9663, Accuracy: 92.21%\n",
      "Epoch [5/5], Step [110/129], Loss: 1.9348, Accuracy: 92.24%\n",
      "Epoch [5/5], Step [120/129], Loss: 1.9441, Accuracy: 92.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] Eval Loss: 2.2181, Eval Accuracy: 82.41%, Precision: 0.85, Recall: 0.82, F1-Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# train_loop\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=5e-5, \n",
    "    betas=betas, \n",
    "    eps=eps\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义学习率调度器\n",
    "def lr_lambda(current_step: int):\n",
    "    return max(0.0, 1.0 - current_step / num_steps)\n",
    "\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "total_steps = len(train_loader)  # 每个epoch的训练步数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if (step + 1) % 10 == 0:\n",
    "            avg_loss = running_loss / 10\n",
    "            acc = 100 * correct / total\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{total_steps}], Loss: {avg_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "            writer.add_scalar(\"Training/Loss\", avg_loss, epoch * total_steps + step)\n",
    "            writer.add_scalar(\"Training/Accuracy\", acc, epoch * total_steps + step)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    writer.add_scalar(\"Training/Precision\", precision, epoch)\n",
    "    writer.add_scalar(\"Training/Recall\", recall, epoch)\n",
    "    writer.add_scalar(\"Training/F1-Score\", f1, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_preds.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    eval_loss /= len(val_loader)\n",
    "    eval_acc = 100 * correct / total\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(val_labels, val_preds, average=\"weighted\",zero_division=1)\n",
    "    conf_matrix = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "    writer.add_scalar(\"Validation/Loss\", eval_loss, epoch)\n",
    "    writer.add_scalar(\"Validation/Accuracy\", eval_acc, epoch)\n",
    "    writer.add_scalar(\"Validation/Precision\", precision, epoch)\n",
    "    writer.add_scalar(\"Validation/Recall\", recall, epoch)\n",
    "    writer.add_scalar(\"Validation/F1-Score\", f1, epoch)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    writer.add_figure(\"Validation/Confusion_Matrix\", plt.gcf(), epoch)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Eval Loss: {eval_loss:.4f}, Eval Accuracy: {eval_acc:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8489bbd3-0039-42ae-b188-91ac6f494980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:5055: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/models/vit/modeling_vit.py:172: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/models/vit/modeling_vit.py:178: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if height != self.image_size[0] or width != self.image_size[1]:\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir='./runs/vit_finetune')\n",
    "example_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.model(x).logits\n",
    "\n",
    "\n",
    "wrapped_model = WrappedModel(model)\n",
    "\n",
    "\n",
    "writer.add_graph(wrapped_model, example_input)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570b91a-f1bc-4b6d-9a4f-3182dbb4349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!poweroff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0878c039-8629-4e94-9888-37eec3150edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"vit_finetuned_StanfordDogs_ep5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda07042-c614-4213-a4fc-1474b207cea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
